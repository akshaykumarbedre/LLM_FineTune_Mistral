{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "140783c9-189b-4ac9-bf75-02ff5df7e1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.12/lib/python3.12/site-packages/redis/connection.py:77: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "  warnings.warn(msg)\n",
      "Ignoring files matching the following patterns: None\n",
      ".gitattributes: 100%|██████████████████████| 1.57k/1.57k [00:00<00:00, 22.1MB/s]\n",
      "README.md: 100%|████████████████████████████| 29.1k/29.1k [00:00<00:00, 165MB/s]\n",
      "config.json: 100%|█████████████████████████████| 838/838 [00:00<00:00, 16.0MB/s]\n",
      "generation_config.json: 100%|██████████████████| 187/187 [00:00<00:00, 1.19MB/s]\n",
      "model-00001-of-00002.safetensors:  48%|█▉  | 2.42G/4.99G [00:02<00:02, 1.27GB/s]/opt/conda/envs/py_3.12/lib/python3.12/site-packages/redis/connection.py:77: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "  warnings.warn(msg)\n",
      "model-00001-of-00002.safetensors: 100%|████| 4.99G/4.99G [00:03<00:00, 1.62GB/s]\n",
      "model-00002-of-00002.safetensors: 100%|███████| 241M/241M [00:00<00:00, 384MB/s]\n",
      "model.safetensors.index.json: 100%|█████████| 24.2k/24.2k [00:00<00:00, 190MB/s]\n",
      "special_tokens_map.json: 100%|█████████████████| 636/636 [00:00<00:00, 9.43MB/s]\n",
      "tokenizer.json: 100%|██████████████████████| 17.5M/17.5M [00:00<00:00, 57.2MB/s]\n",
      "tokenizer.model: 100%|█████████████████████| 4.24M/4.24M [00:00<00:00, 8.28MB/s]\n",
      "tokenizer_config.json: 100%|███████████████| 47.0k/47.0k [00:00<00:00, 1.13MB/s]\n",
      "Successfully downloaded model repo and wrote to the following locations:\n",
      "/tmp/gemma-2-2b-it/README.md\n",
      "/tmp/gemma-2-2b-it/generation_config.json\n",
      "/tmp/gemma-2-2b-it/.gitattributes\n",
      "/tmp/gemma-2-2b-it/tokenizer_config.json\n",
      "/tmp/gemma-2-2b-it/tokenizer.json\n",
      "/tmp/gemma-2-2b-it/.cache\n",
      "/tmp/gemma-2-2b-it/special_tokens_map.json\n",
      "/tmp/gemma-2-2b-it/model-00001-of-00002.safetensors\n",
      "/tmp/gemma-2-2b-it/original_repo_id.json\n",
      "/tmp/gemma-2-2b-it/model-00002-of-00002.safetensors\n",
      "/tmp/gemma-2-2b-it/config.json\n",
      "/tmp/gemma-2-2b-it/model.safetensors.index.json\n",
      "/tmp/gemma-2-2b-it/tokenizer.model\n"
     ]
    }
   ],
   "source": [
    "!tune download google/gemma-2-2b-it\\\n",
    "    --hf-token <hf token >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bd11b7f-7ef4-4594-a224-ff10ce702557",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.12/lib/python3.12/site-packages/redis/connection.py:77: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "  warnings.warn(msg)\n",
      "RECIPE                                   CONFIG                                  \n",
      "full_finetune_single_device              llama2/7B_full_low_memory               \n",
      "                                         code_llama2/7B_full_low_memory          \n",
      "                                         llama3/8B_full_single_device            \n",
      "                                         llama3_1/8B_full_single_device          \n",
      "                                         llama3_2/1B_full_single_device          \n",
      "                                         llama3_2/3B_full_single_device          \n",
      "                                         mistral/7B_full_low_memory              \n",
      "                                         phi3/mini_full_low_memory               \n",
      "                                         phi4/14B_full_low_memory                \n",
      "                                         qwen2/7B_full_single_device             \n",
      "                                         qwen2/0.5B_full_single_device           \n",
      "                                         qwen2/1.5B_full_single_device           \n",
      "                                         qwen2_5/0.5B_full_single_device         \n",
      "                                         qwen2_5/1.5B_full_single_device         \n",
      "                                         qwen2_5/3B_full_single_device           \n",
      "                                         qwen2_5/7B_full_single_device           \n",
      "                                         llama3_2_vision/11B_full_single_device  \n",
      "full_finetune_distributed                llama2/7B_full                          \n",
      "                                         llama2/13B_full                         \n",
      "                                         llama3/8B_full                          \n",
      "                                         llama3_1/8B_full                        \n",
      "                                         llama3_2/1B_full                        \n",
      "                                         llama3_2/3B_full                        \n",
      "                                         llama3/70B_full                         \n",
      "                                         llama3_1/70B_full                       \n",
      "                                         llama3_3/70B_full                       \n",
      "                                         llama3_3/70B_full_multinode             \n",
      "                                         mistral/7B_full                         \n",
      "                                         gemma/2B_full                           \n",
      "                                         gemma/7B_full                           \n",
      "                                         gemma2/2B_full                          \n",
      "                                         gemma2/9B_full                          \n",
      "                                         gemma2/27B_full                         \n",
      "                                         phi3/mini_full                          \n",
      "                                         phi4/14B_full                           \n",
      "                                         qwen2/7B_full                           \n",
      "                                         qwen2/0.5B_full                         \n",
      "                                         qwen2/1.5B_full                         \n",
      "                                         qwen2_5/0.5B_full                       \n",
      "                                         qwen2_5/1.5B_full                       \n",
      "                                         qwen2_5/3B_full                         \n",
      "                                         qwen2_5/7B_full                         \n",
      "                                         llama3_2_vision/11B_full                \n",
      "                                         llama3_2_vision/90B_full                \n",
      "lora_finetune_single_device              llama2/7B_lora_single_device            \n",
      "                                         llama2/7B_qlora_single_device           \n",
      "                                         code_llama2/7B_lora_single_device       \n",
      "                                         code_llama2/7B_qlora_single_device      \n",
      "                                         llama3/8B_lora_single_device            \n",
      "                                         llama3_1/8B_lora_single_device          \n",
      "                                         llama3/8B_qlora_single_device           \n",
      "                                         llama3_2/1B_lora_single_device          \n",
      "                                         llama3_2/3B_lora_single_device          \n",
      "                                         llama3/8B_dora_single_device            \n",
      "                                         llama3/8B_qdora_single_device           \n",
      "                                         llama3_1/8B_qlora_single_device         \n",
      "                                         llama3_2/1B_qlora_single_device         \n",
      "                                         llama3_2/3B_qlora_single_device         \n",
      "                                         llama2/13B_qlora_single_device          \n",
      "                                         mistral/7B_lora_single_device           \n",
      "                                         mistral/7B_qlora_single_device          \n",
      "                                         gemma/2B_lora_single_device             \n",
      "                                         gemma/2B_qlora_single_device            \n",
      "                                         gemma/7B_lora_single_device             \n",
      "                                         gemma/7B_qlora_single_device            \n",
      "                                         gemma2/2B_lora_single_device            \n",
      "                                         gemma2/2B_qlora_single_device           \n",
      "                                         gemma2/9B_lora_single_device            \n",
      "                                         gemma2/9B_qlora_single_device           \n",
      "                                         gemma2/27B_lora_single_device           \n",
      "                                         gemma2/27B_qlora_single_device          \n",
      "                                         phi3/mini_lora_single_device            \n",
      "                                         phi3/mini_qlora_single_device           \n",
      "                                         phi4/14B_lora_single_device             \n",
      "                                         phi4/14B_qlora_single_device            \n",
      "                                         qwen2/7B_lora_single_device             \n",
      "                                         qwen2/0.5B_lora_single_device           \n",
      "                                         qwen2/1.5B_lora_single_device           \n",
      "                                         qwen2_5/0.5B_lora_single_device         \n",
      "                                         qwen2_5/1.5B_lora_single_device         \n",
      "                                         qwen2_5/3B_lora_single_device           \n",
      "                                         qwen2_5/7B_lora_single_device           \n",
      "                                         qwen2_5/14B_lora_single_device          \n",
      "                                         llama3_2_vision/11B_lora_single_device  \n",
      "                                         llama3_2_vision/11B_qlora_single_device \n",
      "lora_dpo_single_device                   llama2/7B_lora_dpo_single_device        \n",
      "                                         llama3_1/8B_lora_dpo_single_device      \n",
      "lora_dpo_distributed                     llama2/7B_lora_dpo                      \n",
      "                                         llama3_1/8B_lora_dpo                    \n",
      "full_dpo_distributed                     llama3_1/8B_full_dpo                    \n",
      "ppo_full_finetune_single_device          mistral/7B_full_ppo_low_memory          \n",
      "lora_finetune_distributed                llama2/7B_lora                          \n",
      "                                         llama2/13B_lora                         \n",
      "                                         llama2/70B_lora                         \n",
      "                                         llama2/7B_qlora                         \n",
      "                                         llama2/70B_qlora                        \n",
      "                                         llama3/8B_dora                          \n",
      "                                         llama3/70B_lora                         \n",
      "                                         llama3_1/70B_lora                       \n",
      "                                         llama3_3/70B_lora                       \n",
      "                                         llama3_3/70B_qlora                      \n",
      "                                         llama3/8B_lora                          \n",
      "                                         llama3_1/8B_lora                        \n",
      "                                         llama3_2/1B_lora                        \n",
      "                                         llama3_2/3B_lora                        \n",
      "                                         llama3_1/405B_qlora                     \n",
      "                                         mistral/7B_lora                         \n",
      "                                         gemma/2B_lora                           \n",
      "                                         gemma/7B_lora                           \n",
      "                                         gemma2/2B_lora                          \n",
      "                                         gemma2/9B_lora                          \n",
      "                                         gemma2/27B_lora                         \n",
      "                                         phi3/mini_lora                          \n",
      "                                         phi4/14B_lora                           \n",
      "                                         qwen2/7B_lora                           \n",
      "                                         qwen2/0.5B_lora                         \n",
      "                                         qwen2/1.5B_lora                         \n",
      "                                         qwen2_5/0.5B_lora                       \n",
      "                                         qwen2_5/1.5B_lora                       \n",
      "                                         qwen2_5/3B_lora                         \n",
      "                                         qwen2_5/7B_lora                         \n",
      "                                         qwen2_5/32B_lora                        \n",
      "                                         qwen2_5/72B_lora                        \n",
      "                                         llama3_2_vision/11B_lora                \n",
      "                                         llama3_2_vision/11B_qlora               \n",
      "                                         llama3_2_vision/90B_lora                \n",
      "                                         llama3_2_vision/90B_qlora               \n",
      "dev/lora_finetune_distributed_multi_dataset dev/11B_lora_multi_dataset              \n",
      "generate                                 generation                              \n",
      "dev/generate_v2                          llama2/generation_v2                    \n",
      "                                         llama3_2_vision/11B_generation_v2       \n",
      "dev/generate_v2_distributed              llama3/70B_generation_distributed       \n",
      "                                         llama3_1/70B_generation_distributed     \n",
      "                                         llama3_3/70B_generation_distributed     \n",
      "dev/early_exit_finetune_distributed      llama2/7B_full_early_exit               \n",
      "eleuther_eval                            eleuther_evaluation                     \n",
      "                                         llama3_2_vision/11B_evaluation          \n",
      "                                         qwen2/evaluation                        \n",
      "                                         qwen2_5/evaluation                      \n",
      "                                         gemma/evaluation                        \n",
      "                                         phi4/evaluation                         \n",
      "                                         phi3/evaluation                         \n",
      "                                         mistral/evaluation                      \n",
      "                                         llama3_2/evaluation                     \n",
      "                                         code_llama2/evaluation                  \n",
      "quantize                                 quantization                            \n",
      "qat_distributed                          llama2/7B_qat_full                      \n",
      "                                         llama3/8B_qat_full                      \n",
      "qat_lora_finetune_distributed            llama3/8B_qat_lora                      \n",
      "                                         llama3_1/8B_qat_lora                    \n",
      "                                         llama3_2/1B_qat_lora                    \n",
      "                                         llama3_2/3B_qat_lora                    \n",
      "knowledge_distillation_single_device     qwen2/1.5_to_0.5B_KD_lora_single_device \n",
      "                                         llama3_2/8B_to_1B_KD_lora_single_device \n",
      "knowledge_distillation_distributed       qwen2/1.5_to_0.5B_KD_lora_distributed   \n",
      "                                         llama3_2/8B_to_1B_KD_lora_distributed   \n"
     ]
    }
   ],
   "source": [
    "!tune ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86a91376-d530-4f88-b7c5-8badb5de8a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.12/lib/python3.12/site-packages/redis/connection.py:77: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "  warnings.warn(msg)\n",
      "Copied file to gemma2bconfig.yaml\n"
     ]
    }
   ],
   "source": [
    "!tune cp  gemma2/2B_lora_single_device gemma2bconfig.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50e497f3-b245-4cb1-a57b-095298920f04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.12/lib/python3.12/site-packages/redis/connection.py:77: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "  warnings.warn(msg)\n",
      "INFO:torchtune.utils._logging:Running LoRAFinetuneRecipeSingleDevice with resolved config:\n",
      "\n",
      "batch_size: 15\n",
      "checkpointer:\n",
      "  _component_: torchtune.training.FullModelHFCheckpointer\n",
      "  checkpoint_dir: /tmp/gemma-2-2b-it\n",
      "  checkpoint_files:\n",
      "  - model-00001-of-00002.safetensors\n",
      "  - model-00002-of-00002.safetensors\n",
      "  model_type: GEMMA2\n",
      "  output_dir: /tmp/tune/gemma-2-2b-it\n",
      "  recipe_checkpoint: null\n",
      "clip_grad_norm: null\n",
      "compile: false\n",
      "dataset:\n",
      "  _component_: torchtune.datasets.alpaca_dataset\n",
      "  column_map:\n",
      "    input: input\n",
      "    output: output\n",
      "  data_files: data/database.json\n",
      "  packed: false\n",
      "  source: json\n",
      "  split: train\n",
      "  train_on_input: true\n",
      "device: cuda\n",
      "dtype: bf16\n",
      "enable_activation_checkpointing: true\n",
      "enable_activation_offloading: false\n",
      "epochs: 80\n",
      "gradient_accumulation_steps: 8\n",
      "log_every_n_steps: 1\n",
      "log_peak_memory_stats: true\n",
      "loss:\n",
      "  _component_: torchtune.modules.loss.CEWithChunkedOutputLoss\n",
      "lr_scheduler:\n",
      "  _component_: torchtune.training.lr_schedulers.get_cosine_schedule_with_warmup\n",
      "  num_warmup_steps: 10\n",
      "max_steps_per_epoch: null\n",
      "metric_logger:\n",
      "  _component_: torchtune.training.metric_logging.DiskLogger\n",
      "  log_dir: /tmp/torchtune/gemma2_2B/lora_single_device/logs\n",
      "model:\n",
      "  _component_: torchtune.models.gemma2.lora_gemma2_2b\n",
      "  apply_lora_to_mlp: true\n",
      "  lora_alpha: 512\n",
      "  lora_attn_modules:\n",
      "  - q_proj\n",
      "  - v_proj\n",
      "  - output_proj\n",
      "  lora_dropout: 0.0\n",
      "  lora_rank: 256\n",
      "optimizer:\n",
      "  _component_: torch.optim.AdamW\n",
      "  fused: true\n",
      "  lr: 2.0e-05\n",
      "output_dir: /tmp/torchtune/gemma2_2B/lora_single_device\n",
      "profiler:\n",
      "  _component_: torchtune.training.setup_torch_profiler\n",
      "  active_steps: 2\n",
      "  cpu: true\n",
      "  cuda: true\n",
      "  enabled: false\n",
      "  num_cycles: 1\n",
      "  output_dir: /tmp/torchtune/gemma2_2B/lora_single_device/profiling_outputs\n",
      "  profile_memory: false\n",
      "  record_shapes: true\n",
      "  wait_steps: 5\n",
      "  warmup_steps: 5\n",
      "  with_flops: false\n",
      "  with_stack: false\n",
      "resume_from_checkpoint: false\n",
      "save_adapter_weights_only: false\n",
      "seed: null\n",
      "shuffle: true\n",
      "tokenizer:\n",
      "  _component_: torchtune.models.gemma.gemma_tokenizer\n",
      "  path: /tmp/gemma-2-2b-it/tokenizer.model\n",
      "\n",
      "DEBUG:torchtune.utils._logging:Setting manual seed to local seed 2382139440. Local seed is seed + rank = 2382139440 + 0\n",
      "INFO:torchtune.utils._logging:Hint: enable_activation_checkpointing is True, but enable_activation_offloading isn't. Enabling activation offloading should reduce memory further.\n",
      "Writing logs to /tmp/torchtune/gemma2_2B/lora_single_device/logs/log_1753938137.txt\n",
      "INFO:torchtune.utils._logging:Model is initialized with precision torch.bfloat16.\n",
      "INFO:torchtune.utils._logging:Memory stats after model init:\n",
      "\tGPU peak memory allocation: 5.74 GiB\n",
      "\tGPU peak memory reserved: 5.79 GiB\n",
      "\tGPU peak memory active: 5.74 GiB\n",
      "INFO:torchtune.utils._logging:Tokenizer is initialized from file.\n",
      "INFO:torchtune.utils._logging:Optimizer and loss are initialized.\n",
      "INFO:torchtune.utils._logging:Loss is initialized.\n",
      "INFO:torchtune.utils._logging:Learning rate scheduler is initialized.\n",
      "WARNING:torchtune.utils._logging: Profiling disabled.\n",
      "INFO:torchtune.utils._logging: Profiler config after instantiation: {'enabled': False}\n",
      "0it [00:00, ?it/s]/opt/conda/envs/py_3.12/lib/python3.12/site-packages/redis/connection.py:77: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "  warnings.warn(msg)\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_0/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_0/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_0/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_0/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_0/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 10.88 seconds.\n",
      "\n",
      "0it [00:19, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_1/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_1/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_1/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_1/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_1/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.97 seconds.\n",
      "0it [00:08, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_2/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_2/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_2/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_2/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_2/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.59 seconds.\n",
      "\n",
      "0it [00:07, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_3/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_3/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_3/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_3/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_3/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.64 seconds.\n",
      "0it [00:07, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_4/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_4/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_4/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_4/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_4/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.74 seconds.\n",
      "\n",
      "0it [00:07, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_5/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_5/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_5/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_5/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_5/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 8.65 seconds.\n",
      "0it [00:09, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_6/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_6/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_6/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_6/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_6/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 8.12 seconds.\n",
      "\n",
      "0it [00:08, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_7/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_7/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_7/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_7/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_7/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.63 seconds.\n",
      "0it [00:07, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_8/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_8/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_8/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_8/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_8/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.73 seconds.\n",
      "\n",
      "0it [00:08, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_9/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_9/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_9/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_9/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_9/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.71 seconds.\n",
      "0it [00:08, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_10/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_10/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_10/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_10/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_10/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 8.15 seconds.\n",
      "\n",
      "0it [00:08, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_11/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_11/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_11/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_11/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_11/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 8.32 seconds.\n",
      "0it [00:08, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_12/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_12/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_12/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_12/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_12/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 9.40 seconds.\n",
      "\n",
      "0it [00:09, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_13/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_13/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_13/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_13/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_13/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 8.81 seconds.\n",
      "0it [00:09, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_14/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_14/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_14/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_14/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_14/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 10.38 seconds.\n",
      "\n",
      "0it [00:10, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_15/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_15/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_15/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_15/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_15/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 8.22 seconds.\n",
      "0it [00:08, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_16/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_16/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_16/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_16/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_16/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 8.75 seconds.\n",
      "\n",
      "0it [00:09, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_17/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_17/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_17/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_17/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_17/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.54 seconds.\n",
      "0it [00:07, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_18/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_18/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_18/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_18/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_18/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.65 seconds.\n",
      "\n",
      "0it [00:07, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_19/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_19/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_19/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_19/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_19/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.73 seconds.\n",
      "0it [00:10, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_20/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_20/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_20/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_20/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_20/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 8.11 seconds.\n",
      "\n",
      "0it [00:08, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_21/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_21/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_21/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_21/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_21/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.67 seconds.\n",
      "0it [00:08, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_22/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_22/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_22/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_22/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_22/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.75 seconds.\n",
      "\n",
      "0it [00:08, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_23/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_23/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_23/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_23/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_23/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 8.38 seconds.\n",
      "0it [00:08, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_24/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_24/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_24/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_24/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_24/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 8.28 seconds.\n",
      "\n",
      "0it [00:08, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_25/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_25/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_25/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_25/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_25/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 8.47 seconds.\n",
      "0it [00:08, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_26/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_26/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_26/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_26/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_26/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.78 seconds.\n",
      "\n",
      "0it [00:08, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_27/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_27/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_27/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_27/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_27/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 8.29 seconds.\n",
      "0it [00:08, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_28/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_28/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_28/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_28/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_28/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.60 seconds.\n",
      "\n",
      "0it [00:08, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_29/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_29/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_29/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_29/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_29/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.74 seconds.\n",
      "0it [00:08, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_30/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_30/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_30/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_30/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_30/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.69 seconds.\n",
      "\n",
      "0it [00:07, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_31/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_31/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_31/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_31/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_31/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 8.19 seconds.\n",
      "0it [00:08, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_32/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_32/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_32/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_32/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_32/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.70 seconds.\n",
      "\n",
      "0it [00:07, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_33/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_33/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_33/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_33/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_33/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.71 seconds.\n",
      "0it [00:08, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_34/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_34/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_34/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_34/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_34/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.74 seconds.\n",
      "\n",
      "0it [00:08, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_35/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_35/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_35/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_35/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_35/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.71 seconds.\n",
      "0it [00:08, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_36/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_36/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_36/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_36/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_36/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 8.05 seconds.\n",
      "\n",
      "0it [00:08, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_37/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_37/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_37/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_37/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_37/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.52 seconds.\n",
      "0it [00:07, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_38/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_38/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_38/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_38/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_38/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.62 seconds.\n",
      "\n",
      "0it [00:07, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_39/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_39/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_39/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_39/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_39/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 8.20 seconds.\n",
      "0it [00:08, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_40/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_40/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_40/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_40/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_40/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.57 seconds.\n",
      "\n",
      "0it [00:07, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_41/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_41/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_41/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_41/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_41/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.54 seconds.\n",
      "0it [00:07, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_42/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_42/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_42/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_42/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_42/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.57 seconds.\n",
      "\n",
      "0it [00:07, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_43/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_43/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_43/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_43/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_43/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.67 seconds.\n",
      "0it [00:07, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_44/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_44/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_44/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_44/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_44/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 8.07 seconds.\n",
      "\n",
      "0it [00:08, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_45/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_45/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_45/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_45/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_45/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 8.15 seconds.\n",
      "0it [00:08, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_46/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_46/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_46/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_46/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_46/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 10.16 seconds.\n",
      "\n",
      "0it [00:10, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_47/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_47/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_47/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_47/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_47/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 10.53 seconds.\n",
      "0it [00:10, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_48/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_48/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_48/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_48/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_48/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 11.90 seconds.\n",
      "\n",
      "0it [00:12, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_49/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_49/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_49/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_49/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_49/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 8.93 seconds.\n",
      "0it [00:09, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_50/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_50/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_50/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_50/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_50/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.70 seconds.\n",
      "\n",
      "0it [00:10, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_51/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_51/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_51/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_51/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_51/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.79 seconds.\n",
      "0it [00:08, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_52/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_52/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_52/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_52/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_52/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 8.22 seconds.\n",
      "\n",
      "0it [00:08, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_53/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_53/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_53/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_53/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_53/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.70 seconds.\n",
      "0it [00:07, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_54/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_54/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_54/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_54/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_54/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.53 seconds.\n",
      "\n",
      "0it [00:07, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_55/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_55/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_55/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_55/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_55/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.43 seconds.\n",
      "0it [00:07, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_56/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_56/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_56/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_56/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_56/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.62 seconds.\n",
      "\n",
      "0it [00:07, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_57/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_57/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_57/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_57/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_57/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.61 seconds.\n",
      "0it [00:07, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_58/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_58/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_58/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_58/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_58/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 8.05 seconds.\n",
      "\n",
      "0it [00:08, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_59/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_59/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_59/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_59/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_59/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.60 seconds.\n",
      "0it [00:07, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_60/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_60/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_60/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_60/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_60/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.59 seconds.\n",
      "\n",
      "0it [00:07, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_61/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_61/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_61/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_61/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_61/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.52 seconds.\n",
      "0it [00:07, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_62/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_62/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_62/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_62/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_62/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 8.12 seconds.\n",
      "\n",
      "0it [00:08, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_63/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_63/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_63/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_63/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_63/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.54 seconds.\n",
      "0it [00:07, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_64/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_64/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_64/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_64/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_64/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.49 seconds.\n",
      "\n",
      "0it [00:07, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_65/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_65/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_65/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_65/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_65/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.61 seconds.\n",
      "0it [00:07, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_66/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_66/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_66/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_66/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_66/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.98 seconds.\n",
      "\n",
      "0it [00:08, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_67/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_67/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_67/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_67/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_67/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.61 seconds.\n",
      "0it [00:07, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_68/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_68/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_68/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_68/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_68/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.66 seconds.\n",
      "\n",
      "0it [00:07, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_69/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_69/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_69/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_69/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_69/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.54 seconds.\n",
      "0it [00:07, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_70/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_70/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_70/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_70/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_70/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 8.15 seconds.\n",
      "\n",
      "0it [00:08, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_71/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_71/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_71/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_71/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_71/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.51 seconds.\n",
      "0it [00:07, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_72/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_72/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_72/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_72/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_72/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.63 seconds.\n",
      "\n",
      "0it [00:07, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_73/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_73/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_73/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_73/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_73/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.65 seconds.\n",
      "0it [00:07, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_74/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_74/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_74/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_74/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_74/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 8.27 seconds.\n",
      "\n",
      "0it [00:08, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_75/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_75/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_75/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_75/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_75/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.68 seconds.\n",
      "0it [00:07, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_76/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_76/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_76/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_76/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_76/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.55 seconds.\n",
      "\n",
      "0it [00:07, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_77/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_77/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_77/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_77/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_77/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.70 seconds.\n",
      "0it [00:07, ?it/s]\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_78/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_78/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_78/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_78/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_78/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Recipe checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/recipe_state/recipe_state.pt\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.84 seconds.\n",
      "\n",
      "0it [00:08, ?it/s]\u001b[A\n",
      "INFO:torchtune.utils._logging:Starting checkpoint save...\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 4.65 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_79/model-00001-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Model checkpoint of size 0.22 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_79/model-00002-of-00002.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_79/adapter_model.pt\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.58 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_79/adapter_model.safetensors\n",
      "INFO:torchtune.utils._logging:Adapter checkpoint of size 0.00 GiB saved to /tmp/tune/gemma-2-2b-it/epoch_79/adapter_config.json\n",
      "INFO:torchtune.utils._logging:Saving final epoch checkpoint.\n",
      "INFO:torchtune.utils._logging:The full model checkpoint, including all weights and configurations, has been saved successfully.You can now use this checkpoint for further training or inference.\n",
      "INFO:torchtune.utils._logging:Checkpoint saved in 7.62 seconds.\n",
      "0it [00:08, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "!tune run lora_finetune_single_device --config gemma2/2B_lora_single_device batch_size=10 \\\n",
    "    checkpointer.checkpoint_dir=/tmp/gemma-2-2b-it \\\n",
    "    checkpointer.checkpoint_files=\"[model-00001-of-00002.safetensors,model-00002-of-00002.safetensors]\" \\\n",
    "    tokenizer.path=/tmp/gemma-2-2b-it/tokenizer.model \\\n",
    "    checkpointer.output_dir=/tmp/tune/gemma-2-2b-it \\\n",
    "    dataset.source=json \\\n",
    "    dataset.data_files=data/database.json\\\n",
    "    dataset.split=train \\\n",
    "    dataset.train_on_input=True \\\n",
    "    dataset.column_map.input=input \\\n",
    "    dataset.column_map.output=output \\\n",
    "    epochs=100 \\\n",
    "    model.lora_rank=256 \\\n",
    "    model.lora_alpha=512 \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5dfb98b-e2fd-4a15-ad28-5f8b95ac63bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.12/lib/python3.12/site-packages/redis/connection.py:77: UserWarning: redis-py works best with hiredis. Please consider installing\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47eb356e646a46389a9ed069db082bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "#TODO: update it to your chosen epoch\n",
    "trained_model_path = \"/tmp/tune/gemma-2-2b-it/epoch_79\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=trained_model_path,\n",
    ")\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(trained_model_path, safetensors=True)\n",
    "\n",
    "\n",
    "# Function to generate text\n",
    "def generate_text(model, tokenizer, prompt, max_length=1000):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs, max_length=max_length)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10ad7c98-2e3d-427f-8abd-3c001320c1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model output: You are a database agent. Based on the user's question, identify the database tables required to find the answer. Do not write the SQL query. Just list the tables, query : Find all students majoring in 'Computer Science' who received a grade of 'A' in any course during the 'Fall 2024' semester.\n",
      "\n",
      "**Tables:**\n",
      "\n",
      "* Students\n",
      "* Courses\n",
      "* Grades\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "To answer the question, we need to combine information from three tables:\n",
      "\n",
      "* **Students:** To get the student IDs.\n",
      "* **Courses:** To get the course IDs and names.\n",
      "* **Grades:** To get the grade and course IDs. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = \"You are a database agent. Based on the user's question, identify the database tables required to find the answer. Do not write the SQL query. Just list the tables, \\\n",
    "query : Find all students majoring in 'Computer Science' who received a grade of 'A' in any course during the 'Fall 2024' semester\"\n",
    "print(\"Base model output:\", generate_text(model, tokenizer, prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0710266f-722d-492e-976a-54c0d79d5f74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
